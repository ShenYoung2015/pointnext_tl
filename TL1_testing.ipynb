{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointNeXt(\n",
       "  (mlp): Conv1d(6, 32, kernel_size=(1,), stride=(1,))\n",
       "  (stage): ModuleList(\n",
       "    (0): Stage(\n",
       "      (sa): SetAbstraction(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(35, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (irm): Sequential(\n",
       "        (0): InvResMLP(\n",
       "          (la): LocalAggregation(\n",
       "            (mlp): Sequential(\n",
       "              (0): Conv2d(67, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (pw_conv): Sequential(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Stage(\n",
       "      (sa): SetAbstraction(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(67, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (irm): Sequential(\n",
       "        (0): InvResMLP(\n",
       "          (la): LocalAggregation(\n",
       "            (mlp): Sequential(\n",
       "              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (pw_conv): Sequential(\n",
       "            (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): InvResMLP(\n",
       "          (la): LocalAggregation(\n",
       "            (mlp): Sequential(\n",
       "              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (pw_conv): Sequential(\n",
       "            (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Stage(\n",
       "      (sa): SetAbstraction(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(131, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (irm): Sequential(\n",
       "        (0): InvResMLP(\n",
       "          (la): LocalAggregation(\n",
       "            (mlp): Sequential(\n",
       "              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (pw_conv): Sequential(\n",
       "            (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Stage(\n",
       "      (sa): SetAbstraction(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(259, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (irm): Sequential(\n",
       "        (0): InvResMLP(\n",
       "          (la): LocalAggregation(\n",
       "            (mlp): Sequential(\n",
       "              (0): Conv2d(515, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (pw_conv): Sequential(\n",
       "            (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): FeaturePropagation(\n",
       "      (mlp_modules): Sequential(\n",
       "        (0): Conv1d(768, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): FeaturePropagation(\n",
       "      (mlp_modules): Sequential(\n",
       "        (0): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): FeaturePropagation(\n",
       "      (mlp_modules): Sequential(\n",
       "        (0): Conv1d(192, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): FeaturePropagation(\n",
       "      (mlp_modules): Sequential(\n",
       "        (0): Conv1d(96, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): RegHead(\n",
       "    (mlp_modules): Sequential(\n",
       "      (0): Conv1d(32, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from Model import PointNeXt\n",
    "# from dataset.FFDshape import FFDshape_ptp\n",
    "from Loss import reg_loss\n",
    "from Transforms import PCDPretreatment, get_data_augment\n",
    "import numpy as np\n",
    "from numpy.core.umath import isnan\n",
    "from Parameters import *\n",
    "sys.path.insert(1, os.path.dirname(os.path.abspath(__name__)))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_cfg = MODEL_CONFIG['basic_c']\n",
    "max_input = model_cfg['max_input']\n",
    "normal = model_cfg['normal']\n",
    "model = PointNeXt(model_cfg).to(device=device)\n",
    "\n",
    "checkpoint_name = 'PointNeXt_shapesffd3_epoch1000.pth'\n",
    "checkpoint_dir = 'result_train//PointNeXt_model=basic_c_ds=shapesffd3_aug=basic_lr=0.001_wd=0.0001_bs=16_AdamW_cosine//'\n",
    "checkpoint_file = checkpoint_dir + checkpoint_name\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FFDshape_eval(Dataset):\n",
    "    def __init__(self, root, transforms=None, split='test', npoints=1024, augment=False, dp=False, normalize=False):\n",
    "        assert(split == 'train' or split == 'test')\n",
    "        self.npoints = npoints\n",
    "        self.transforms = transforms\n",
    "        self.train_files_list = []\n",
    "        self.test_files_list = []\n",
    "        if split == 'train':\n",
    "            self.training = True\n",
    "        elif split == 'test':\n",
    "            self.training = False\n",
    "        \n",
    "        name_list = os.listdir(os.path.join(root,'pc'))\n",
    "        for i in range(len(name_list)):\n",
    "            name_list[i] = os.path.splitext(name_list[i])[0]\n",
    "        \n",
    "        test_files_list = self.read_list_file(name_list, root)\n",
    "        self.test_files_list = test_files_list\n",
    "\n",
    "        # self.train_files_list = train_files_list # train_files_list\n",
    "\n",
    "        self.caches = {}\n",
    "        print(\n",
    "            f'Training {len(self.train_files_list)} shapes. Testing {len(self.test_files_list)} shapes '\n",
    "        )\n",
    "\n",
    "    def read_list_file(self, name_list, root):\n",
    "        # base = os.path.dirname(file_path)\n",
    "        files_list = []\n",
    "        for shape_name in name_list:\n",
    "            cur = os.path.join(root, 'pc', '{}.txt'.format(shape_name))\n",
    "            files_list.append(cur)\n",
    "        return files_list\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index in self.caches:\n",
    "            return self.caches[index]\n",
    "        file = self.pcd[index]\n",
    "        pc = np.loadtxt(file, delimiter=',').astype(np.float32)\n",
    "        xyz_points = pc[:, :6]\n",
    "        gts = pc[:, 6]\n",
    "        s_mesh = pc[:, -1]\n",
    "\n",
    "        # resample\n",
    "        # choice = np.random.choice(len(xyz_points), self.npoints, replace=True)\n",
    "        # xyz_points = xyz_points[choice, :]\n",
    "        # gts = gts[choice]\n",
    "\n",
    "        xyz_points = torch.from_numpy(xyz_points).float()\n",
    "        gts = torch.from_numpy(gts).float()\n",
    "        if self.transforms is not None:\n",
    "            xyz_points, gts = self.transforms(xyz_points, gts)\n",
    "\n",
    "        return xyz_points, gts, s_mesh\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pcd)\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "        self.pcd = self.train_files_list\n",
    "        if self.transforms is not None:\n",
    "            self.transforms.set_mode('train')\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "        self.pcd = self.test_files_list\n",
    "        if self.transforms is not None:\n",
    "            self.transforms.set_mode('eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read *.stl\n",
    "def stl_read(shape_file):\n",
    "    import open3d as o3d\n",
    "    my_mesh = o3d.io.read_triangle_mesh(shape_file)\n",
    "    Points = np.asarray(my_mesh.vertices)\n",
    "    Connectivity = np.asarray(my_mesh.triangles)\n",
    "\n",
    "    # rescale to 25 m in X-axis\n",
    "    rate = 25/((Points[:,0]).max()-(Points[:,0]).min())\n",
    "    Points = Points * rate\n",
    "    Points[:,0] = Points[:,0] - Points[:,0].mean()\n",
    "    \n",
    "    return Points, Connectivity, rate\n",
    "\n",
    "# more feature of pc\n",
    "def ex_feature(Points, Connectivity):\n",
    "    normals = np.zeros(np.shape(Connectivity))\n",
    "    for i in range(len(Connectivity)):\n",
    "        temp1 = np.cross(Points[Connectivity[i,2],:] - Points[Connectivity[i,0],:],\n",
    "            Points[Connectivity[i,1],:] - Points[Connectivity[i,0],:]); # mesh outer direction\n",
    "        normals[i,:] = temp1/np.linalg.norm(temp1,ord=2)\n",
    "    normals = -normals\n",
    "    \n",
    "    # tri face points\n",
    "    Points_tri = np.zeros(np.shape(Connectivity))\n",
    "    for i in range(len(Connectivity)):\n",
    "        Points_tri[i,:] = np.mean(Points[Connectivity[i,:],:],axis=0)\n",
    "\n",
    "    # cal tri-area\n",
    "    tri_point = np.zeros((np.size(Connectivity,0),3,3))\n",
    "    side_len = np.zeros((np.size(Connectivity,0),3))\n",
    "    for i in range(3):\n",
    "        tri_point[:,:,i] = Points[Connectivity[:,i],:]\n",
    "\n",
    "    for i in range(3):\n",
    "        tmp = np.array([i,i+1]).astype(int)\n",
    "        tmp[tmp>=3] = 0\n",
    "        side_len[:,i] = np.sqrt(np.sum(\n",
    "            (tri_point[:,:,tmp[0]] - tri_point[:,:,tmp[1]])**2\n",
    "            ,1))\n",
    "    side_p = np.sum(side_len,1)/2\n",
    "    tri_area = np.sqrt(side_p*\n",
    "        (side_p-side_len[:,0]) *\n",
    "        (side_p-side_len[:,1]) *\n",
    "        (side_p-side_len[:,2]))\n",
    "    tri_area[isnan(tri_area)]=0\n",
    "    return normals, Points_tri, tri_area\n",
    "\n",
    "# rotate Y-axis\n",
    "def rotate_pc(pc, rotation_angle):\n",
    "    \n",
    "    cosval = np.cos(np.deg2rad(rotation_angle))\n",
    "    sinval = np.sin(np.deg2rad(rotation_angle))\n",
    "    rotation_matrix = np.array([[cosval, 0, sinval],\n",
    "                                [0, 1, 0],\n",
    "                                [-sinval, 0, cosval]])\n",
    "    rotated_pc = np.dot(pc, rotation_matrix)\n",
    "    return rotated_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_base = 'D:\\MyCode\\PCdeep_TL\\ShapeGenerator\\shape_set\\waverider\\\\testing_N200_D60_322\\\\'\n",
    "shape_file = shape_base + 'shape_001.stl'\n",
    "\n",
    "# Tri-reading\n",
    "# if shape_file[-3:] == 'stl' or 'ply':\n",
    "#     Points_init, Connectivity, rate = stl_read(shape_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0 shapes. Testing 13 shapes \n"
     ]
    }
   ],
   "source": [
    "pc_root = 'D:\\MyCode\\PCdeep_TL\\shapesffd4\\waverider\\\\testing_N200_D60_322'\n",
    "# transforms = PCDPretreatment(num=1024, down_sample='random', normal=model_cfg['normal'])\n",
    "transforms = None\n",
    "dataset = FFDshape_eval(root=pc_root,split='test',transforms=transforms)\n",
    "dataset.eval()\n",
    "eval_dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=1,\n",
    "                                num_workers=0,\n",
    "                                pin_memory=False,\n",
    "                                drop_last=False,\n",
    "                                shuffle=False)\n",
    "criterion = reg_loss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in eval_dataloader:\n",
    "    pcd, gts, s = data\n",
    "    pcd, gts = pcd.to(device, non_blocking=True), gts.to(device, non_blocking=True)\n",
    "    # with torch.no_grad():\n",
    "    #     pred = model(pcd)\n",
    "    #     pred = torch.squeeze(pred,1)\n",
    "    #     loss = criterion(pred, gts)\n",
    "    count = count + 1\n",
    "    if count>=1:\n",
    "        break\n",
    "\n",
    "Points_init = np.array(pcd.squeeze(0).to('cpu'))\n",
    "import open3d as o3d\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uniform down sample\n",
    "# num_points = 1024\n",
    "# pcd_o3d = o3d.geometry.PointCloud()\n",
    "# pcd_o3d.points = o3d.utility.Vector3dVector(Points_init[:,:3])\n",
    "# pcd_o3d.normals = o3d.utility.Vector3dVector(Points_init[:,3:6])\n",
    "# pcd_new = o3d.geometry.PointCloud.uniform_down_sample(pcd_o3d, floor(len(Points_init)/num_points))# 508\n",
    "# new_points = np.array(pcd_new.points,dtype=float)\n",
    "# new_normals = np.array(pcd_new.normals,dtype=float)\n",
    "# new_points, new_normals = new_points[:num_points], new_normals[:num_points]\n",
    "# pcd_new.points = o3d.utility.Vector3dVector(new_points)\n",
    "# # pcd_new = torch.tensor(np.concatenate((new_points,new_normals),axis=1))\n",
    "# pcd_new = torch.from_numpy(np.concatenate((new_points,new_normals),axis=1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random choose\n",
    "num_points = 1024\n",
    "choice_idx = torch.randperm(pcd.shape[1])[:num_points]\n",
    "pcd_new = Points_init[choice_idx,:]\n",
    "pcd_new = torch.from_numpy(pcd_new).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(pcd_new.T.unsqueeze(0).to(device))\n",
    "    pred = torch.squeeze(pred,1).T\n",
    "    pred = pred.to('cpu')\n",
    "    pcd_new = pcd_new.to('cpu')\n",
    "    # loss = criterion(pred, gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "interp_pred = griddata(pcd_new[:,:3], pred.squeeze(1), Points_init[:,:3], method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=pred.squeeze(1),\n",
    "                 y=gts.to('cpu')[0,choice_idx]\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=interp_pred,\n",
    "                 y=gts.to('cpu')[0]\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "tmp = gts.to('cpu')[0,choice_idx]\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=pcd_new[:,0].to('cpu'),\n",
    "    y=pcd_new[:,1].to('cpu'),\n",
    "    z=pcd_new[:,2].to('cpu'),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=tmp,   # pred[:,0].to('cpu')\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Helix equation\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=Points_init[:,0],\n",
    "    y=Points_init[:,1],\n",
    "    z=Points_init[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color=interp_pred,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
